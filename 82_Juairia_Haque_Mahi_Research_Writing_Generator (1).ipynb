{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ResearchGEN: An AI-assisted Research Writing Generator**"
      ],
      "metadata": {
        "id": "CYTtZ51UpxbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is an AI-powered research writing tool that leverages advanced generative AI models (like Gemini) and real-time search capabilities (TavilySearch) to assist users in generating, researching, and refining academic papers. This model ensures adherence to strict academic formatting and citation standards. Results from TavilySearch are explicitly fed as 'context' to the Gemini model. This process, known as Retrieval-Augmented Generation (RAG), 'grounds' the model's output in verifiable external information. This greatly minimizes the common problem of LLMs 'hallucinating' facts or citations, as it has concrete data to draw from."
      ],
      "metadata": {
        "id": "Yp-GJtJJuzbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation & Import**"
      ],
      "metadata": {
        "id": "WShY7dlGFfDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU google-genai langchain-tavily fpdf pypdf\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "OjBHV5BKFcdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, Markdown\n",
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install python-docx\n",
        "import re\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "from docx.shared import Pt\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "hjZ-MGlCFvuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup**"
      ],
      "metadata": {
        "id": "pOpC_t2vF8LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
        "YOUR_API_KEY = \"AIzaSyAi6PBZXgla3IST_afB4aq9FGf5VxMkwlE\"\n",
        "\n",
        "client = genai.Client(\n",
        "    api_key=YOUR_API_KEY,\n",
        "    http_options=types.HttpOptions(\n",
        "        retry_options=types.HttpRetryOptions(\n",
        "            attempts=5,\n",
        "            initial_delay=2.0,\n",
        "            max_delay=30.0,\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "tq6X8Z_quWo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model & Research Prompt**"
      ],
      "metadata": {
        "id": "AR5Bq8SiGtTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_model():\n",
        "    try:\n",
        "        available = [m.name for m in client.models.list()]\n",
        "        for target in [\"gemini-2.5-flash\", \"gemini-2.5-flash-lite\", \"gemini-1.5-flash\"]:\n",
        "            if any(target in m for m in available): return target\n",
        "        return \"gemini-2.5-flash\"\n",
        "    except:\n",
        "        return \"gemini-2.5-flash\"\n",
        "\n",
        "def conduct_research(topic):\n",
        "    search_tool = TavilySearch(max_results=10, search_depth=\"advanced\")\n",
        "    print(f\"Researching: {topic}...\")\n",
        "\n",
        "    try:\n",
        "        search_data = search_tool.invoke({\"query\": f\"detailed data and facts about {topic}\"})\n",
        "\n",
        "        if not search_data or isinstance(search_data, str):\n",
        "            print(\"Refining search for better coverage...\")\n",
        "            search_data = search_tool.invoke({\"query\": topic})\n",
        "\n",
        "        context_parts = []\n",
        "\n",
        "        results_list = search_data if isinstance(search_data, list) else search_data.get('results', [])\n",
        "\n",
        "        if not results_list:\n",
        "            context_text = \"No specific external sources found. Use general academic knowledge.\"\n",
        "        else:\n",
        "            for i, res in enumerate(results_list):\n",
        "                context_parts.append(f\"SOURCE {i+1}: {res.get('content')} (URL: {res.get('url')})\")\n",
        "            context_text = \"\\n\".join(context_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        context_text = f\"Search system encountered an error, proceeding with internal knowledge. Error: {e}\"\n",
        "\n",
        "    active_model = get_best_model()\n",
        "\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    rules:\n",
        "    {context_text}\n",
        "\n",
        "    STRICT RULES:\n",
        "    1. Every claim MUST be backed with real standard citation from publicly accessible papers, e.g. [Author_Name, Year].\n",
        "    2. If a fact is from multiple papers, use the most popular and contextually relevant citations.\n",
        "    3. Include a 'References' section at the end with standard APA/MLA references provided.\n",
        "    4. If the sources do not contain the answer, say you do not know.\n",
        "    5. Citations must be shown after every claim made. Not like this [1],[2]. But like this [Author Name, Year]. This rule must be followed and cannot be broken.\n",
        "    6. Follow this structure for all research writing, but have as much detail as possible embedded in each section, elaborately write especially the literature review with multiple aspects covered for a solid foundation:\n",
        "       Abstract\n",
        "       Introduction\n",
        "       Literature Review\n",
        "       Methodology\n",
        "       Results & Discussion\n",
        "       Gaps & Findings\n",
        "       Conclusion\n",
        "       References\n",
        "\n",
        "    TOPIC: {topic}\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Generating Paper via {active_model}...\")\n",
        "    try:\n",
        "        response = client.models.generate_content(model=active_model, contents=prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"❌ Generation Error: {e}\"\n"
      ],
      "metadata": {
        "id": "3Nm-DIH7-FDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paper Generation**"
      ],
      "metadata": {
        "id": "3-1j07T1G92S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_input = widgets.Text(placeholder='Enter topic...', layout={'width': '75%'})\n",
        "btn = widgets.Button(description='Generate Research', button_style='success', icon='check')\n",
        "out = widgets.Output()\n",
        "\n",
        "current_paper_content = \"\"\n",
        "\n",
        "def run_lab(b):\n",
        "    global current_paper_content\n",
        "    with out:\n",
        "        clear_output()\n",
        "        if not topic_input.value: return print(\"⚠️ Please enter a topic.\")\n",
        "        btn.disabled = True\n",
        "        result = conduct_research(topic_input.value)\n",
        "        clear_output()\n",
        "        if result.startswith(DISCLAIMER_TEXT):\n",
        "            result = result[len(DISCLAIMER_TEXT):].strip()\n",
        "        current_paper_content = result\n",
        "        display(Markdown(current_paper_content))\n",
        "        btn.disabled = False"
      ],
      "metadata": {
        "id": "etrpDozvqFwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paper Refinement**\n",
        "\n",
        "This allows the user to iteratively refine and elaborate on the generated paper."
      ],
      "metadata": {
        "id": "i8fQMkj8tqi0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de5a60db"
      },
      "source": [
        "chat_input = widgets.Text(placeholder='Elaborate, refine, or ask a question...', layout={'width': '75%'})\n",
        "chat_btn = widgets.Button(description='Send Prompt', button_style='info', icon='comment')\n",
        "chat_output = widgets.Output()\n",
        "\n",
        "def handle_chat_prompt(b):\n",
        "    global current_paper_content\n",
        "    with chat_output:\n",
        "        clear_output()\n",
        "        if not chat_input.value: return print(\"⚠️ Please enter a prompt.\")\n",
        "\n",
        "        print(f\"User: {chat_input.value}\")\n",
        "        chat_btn.disabled = True\n",
        "\n",
        "\n",
        "        system_prompt = f\"\"\"\n",
        "        You are an AI assistant tasked with refining and elaborating on a research paper.\n",
        "        Below is the current version of the paper. The user will provide instructions on how to modify or elaborate on it.\n",
        "        Your response should be the updated, complete paper, incorporating the user's feedback while maintaining the specified academic structure and citation rules.\n",
        "\n",
        "        Current Paper:\n",
        "        {current_paper_content}\n",
        "\n",
        "        User Instruction: {chat_input.value}\n",
        "\n",
        "        STRICT RULES:\n",
        "        1. Every claim MUST be backed with real standard citation from publicly accessible papers, e.g. [Author_Name, Year].\n",
        "        2. If a fact is from multiple papers, use the most popular and contextually relevant citations.\n",
        "        3. Include a 'References' section at the end with standard APA/MLA references provided.\n",
        "        4. If the sources do not contain the answer, say you do not know.\n",
        "        5. Citations must be shown after every claim made. Not like this [1],[2]. But like this [Author Name, Year]. This rule must be followed and cannot be broken.\n",
        "        6. Follow this structure for all research writing, but have as much detail as possible embedded in each section, elaborately write especially the literature review with multiple aspects covered for a solid foundation:\n",
        "           Abstract\n",
        "           Introduction\n",
        "           Literature Review\n",
        "           Methodology\n",
        "           Results & Discussion\n",
        "           Gaps & Findings\n",
        "           Conclusion\n",
        "           References\n",
        "\n",
        "        Revised Paper based on User Instruction:\n",
        "        \"\"\"\n",
        "\n",
        "        active_model = get_best_model()\n",
        "        print(f\"✍️ Elaborating Paper via {active_model}...\")\n",
        "        try:\n",
        "            response = client.models.generate_content(model=active_model, contents=system_prompt)\n",
        "            new_content = response.text\n",
        "            if new_content.startswith(DISCLAIMER_TEXT):\n",
        "                new_content = new_content[len(DISCLAIMER_TEXT):].strip()\n",
        "            current_paper_content = new_content\n",
        "            clear_output()\n",
        "            display(Markdown(current_paper_content))\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Elaboration Error: {e}\")\n",
        "\n",
        "        chat_input.value = \"\"\n",
        "        chat_btn.disabled = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **UI Interface**"
      ],
      "metadata": {
        "id": "dGqw1Nt8t2t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "btn.on_click(run_lab)\n",
        "display(Markdown(\"## Research Writing Generator\"), widgets.HBox([topic_input, btn]), out)"
      ],
      "metadata": {
        "id": "kkkXkbPf0Q60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_btn.on_click(handle_chat_prompt)\n",
        "display(Markdown(\"### Further Chat Here\"), widgets.HBox([chat_input, chat_btn]), chat_output)"
      ],
      "metadata": {
        "id": "4QRP07gFrC7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Export & Download File**"
      ],
      "metadata": {
        "id": "XJSiOsqa-KFE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "548d47f2"
      },
      "source": [
        "def markdown_to_docx(markdown_content):\n",
        "    document = Document()\n",
        "\n",
        "\n",
        "    document.styles['Normal'].font.name = PDF_FONT_FAMILY\n",
        "    document.styles['Normal'].font.size = Pt(PDF_BODY_FONT_SIZE)\n",
        "\n",
        "    lines = markdown_content.split('\\n')\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        if line.startswith('### '):\n",
        "            document.add_heading(line[4:], level=3)\n",
        "        elif line.startswith('## '):\n",
        "            document.add_heading(line[3:], level=2)\n",
        "        elif line.startswith('# '):\n",
        "            document.add_heading(line[2:], level=1)\n",
        "        else:\n",
        "\n",
        "            p = document.add_paragraph()\n",
        "\n",
        "            parts = re.split(r'(\\**.*?\\**|_.*?_)', line)\n",
        "            for part in parts:\n",
        "                if part.startswith('**') and part.endswith('**'):\n",
        "                    p.add_run(part[2:-2]).bold = True\n",
        "                elif part.startswith('_') and part.endswith('_'):\n",
        "                    p.add_run(part[1:-1]).italic = True\n",
        "                else:\n",
        "                    p.add_run(part)\n",
        "\n",
        "    return document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "230927bb"
      },
      "source": [
        "\n",
        "save_docx_btn = widgets.Button(description='Save as DOCX', button_style='info', icon='file-word')\n",
        "save_docx_output = widgets.Output()\n",
        "\n",
        "def save_paper_as_docx(b):\n",
        "    with save_docx_output:\n",
        "        clear_output()\n",
        "        if not current_paper_content:\n",
        "            print(\"⚠️ No paper content to save. Please generate or refine a paper first.\")\n",
        "            return\n",
        "\n",
        "        print(\"⏳ Converting to DOCX and saving...\")\n",
        "        save_docx_btn.disabled = True\n",
        "\n",
        "        try:\n",
        "            doc = markdown_to_docx(current_paper_content)\n",
        "            file_name = \"research_paper.docx\"\n",
        "            doc.save(file_name)\n",
        "            clear_output()\n",
        "            print(f\"✅ Paper successfully saved as '{file_name}'.\")\n",
        "            files.download(file_name)\n",
        "            print(\"⬇️ Your download should start shortly.\")\n",
        "        except Exception as e:\n",
        "            clear_output()\n",
        "            print(f\"❌ Error saving DOCX: {e}\")\n",
        "        finally:\n",
        "            save_docx_btn.disabled = False\n",
        "\n",
        "save_docx_btn.on_click(save_paper_as_docx)\n",
        "\n",
        "display(Markdown(\"### Export to DOCX\"), widgets.HBox([save_docx_btn]), save_docx_output)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}